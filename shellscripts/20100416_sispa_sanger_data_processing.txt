csh

set sispa_pool_name = 20090205_HIsamples6to100
set sff_file_list = "\
/usr/local/projects/VHTNGS/sample_data/HI_6_100_StandardPipeSFF/454/FTF2AAH01.sff,\
/usr/local/projects/VHTNGS/sample_data/HI_6_100_StandardPipeSFF/454/FTF2AAH02.sff\
"
set fastq_file_list = "\
/usr/local/projects/VHTNGS/sample_data/HI_6_100_StandardPipeSFF/solexa/s_1_1_sequence.txt,\
/usr/local/projects/VHTNGS/sample_data/HI_6_100_StandardPipeSFF/solexa/s_1_2_sequence.txt\
"

set sispa_pool_name = 20090205_34xDW_5xHI_2xUNKNOWN_samples
set sff_file_list = "\
/local/seq454/2009_04_01/R_2009_03_31_15_30_46_FLX01070134_adminrig_033109R1INFLU36R2INFLUPFLU1/D_2009_04_01_01_06_08_dell-2-0-9_signalProcessing/sff/FTFZ1KV01.sff\
"
set fastq_file_list = "\
"

set sispa_pool_name = 20090901_20xDW09_3xCC_12xSW_samples
set sff_file_list = "\
/local/seq454/2009_09_18/R_2009_09_18_10_52_19_FLX01070134_adminrig_091809R1M233R2INFLUSISPA/D_2009_09_18_21_06_55_dell-2-0-4_signalProcessing/sff/F2M4HHZ02.sff\
"
set fastq_file_list = "\
"

set sispa_pool_name = 20091005_AVIAN113
set sff_file_list = "\
/usr/local/projects/VHTNGS/sample_data/AVIAN_113_StandardPipeSFF/454/F66E6K401.sff,\
/usr/local/projects/VHTNGS/sample_data/AVIAN_113_StandardPipeSFF/454/F6PP7OK02.sff\
"
set fastq_file_list = "\
/usr/local/projects/VHTNGS/sample_data/AVIAN_113_StandardPipeSFF/solexa/s_4_1_sequence.txt,\
/usr/local/projects/VHTNGS/sample_data/AVIAN_113_StandardPipeSFF/solexa/s_4_2_sequence.txt\
"


set sispa_pool_name = 20091215_MCEIRSsamples1to50
set sff_file_list = "\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/454/GAC4IF301.sff,\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/454/GAC4IF302.sff\
"
set fastq_file_list = "\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/solexa/s_1_1_sequence.txt,\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/solexa/s_1_2_sequence.txt,\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/solexa/s_2_1_sequence.txt,\
/usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/solexa/s_2_2_sequence.txt\
"


set sispa_pool_name = 20100305_1_86xAK_1xSW
set sff_file_list = "\
/local/seq454/2010_03_25/R_2010_03_25_10_35_08_FLX02080319_Administrator_032510R101XPNR2AVIAN3051/D_2010_03_25_23_49_18_dell-2-0-4_signalProcessing/sff/GEIVOUP02.sff\
"
set fastq_file_list = "\
"

set sispa_pool_name = 20100305_2_32xAK_24xCOH_1xMCWS_2xKHBAT_1xSW
set sff_file_list = "\
/local/seq454/2010_03_26/R_2010_03_26_11_20_10_FLX02080322_adminrig_032610R101XPOR2AVIAN20003052/D_2010_03_26_21_49_18_dell-2-0-3_signalProcessing/sff/GEKSFWC02.sff\
"
set fastq_file_list = "\
"


set project_root = /usr/local/projects/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sispa_data_root = ${project_root}/sispa_data
set sample_data_root = ${project_root}/sample_data

if ( -d ${barcode_data_root} ) then
else
  mkdir -p ${barcode_data_root}
endif
if ( -d ${sispa_data_root} ) then
else
  mkdir -p ${sispa_data_root}
endif
if ( -d ${sample_data_root} ) then
else
  mkdir -p ${sample_data_root}
endif


set max_sol_recs_per_deconv = 1000000

pushd ${project_root}

set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set sispa_data_dir = ${sispa_data_root}/${sispa_pool_name}

if ( -d ${barcode_data_dir} ) then
else
  mkdir -p ${barcode_data_dir}
endif
if ( -d ${sispa_data_dir} ) then
else
  mkdir -p ${sispa_data_dir}
endif

set fastq_dir = ${sispa_data_dir}/fastq
set merged_fastq_dir = ${sispa_data_dir}/merged_fastq
set deconvolved_merged_fastq_dir = ${sispa_data_dir}/deconvolved_merged_fastq

if ( -d ${fastq_dir} ) then
else
  mkdir -p ${fastq_dir}
endif
if ( -d ${merged_fastq_dir} ) then
else
  mkdir -p ${merged_fastq_dir}
endif
if ( -d ${deconvolved_merged_fastq_dir} ) then
else
  mkdir -p ${deconvolved_merged_fastq_dir}
endif

set sff_dir = ${sispa_data_dir}/sff
set merged_sff_dir = ${sispa_data_dir}/merged_sff
set deconvolved_merged_sff_dir = ${sispa_data_dir}/deconvolved_merged_sff

if ( -d ${sff_dir} ) then
else
  mkdir -p ${sff_dir}
endif
if ( -d ${merged_sff_dir} ) then
else
  mkdir -p ${merged_sff_dir}
endif
if ( -d ${deconvolved_merged_sff_dir} ) then
else
  mkdir -p ${deconvolved_merged_sff_dir}
endif

set merged_fastq_file = ${merged_fastq_dir}/merged_solexa_sequence.txt
set merged_sff_file = ${merged_sff_dir}/merged_454.sff

set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt

# build tab-separated-file of barcode metadata based on Excel file attached to 454 BugZero #???
# column order is:
# barcode_name, 
# barcode_sequence, 
# bac_id, 
# blinded_number, 
# species, 
# database_name, 
# collection_name

kedit ${barcode_file_name}

# I used 
# for 20091215_MCEIRSsamples1to50
# cat /usr/local/projects/VHTNGS/sample_data/MCE_1_50_StandardPipeSFF/barcodes/barcode_metadata_from_GLK.txt | \
# gawk '{printf("%s\t%s\t%s\n",$0,"giv3","MCE");}' > ${barcode_file_name}
# for 20090205_HIsamples6to100
# cat /usr/local/projects/VHTNGS/sample_data/HI_6_100_StandardPipeSFF/barcodes/barcode_metadata_from_GLK.txt | \
# gawk '{printf("%s\t%s\t%s\n",$0,"giv3","HI");}' > ${barcode_file_name}
# and for 20091005_AVIAN113
# cat sample_data/AVIAN_113_StandardPipeSFF/barcodes/barcode_metadata_from_GLK.txt | \
#   gawk '{if ($4 ~ /\-AK\-/){c="AK";}\
#          else if($4 ~ /\-RF\-/){c="RF";}\
#          else if($4 ~ /\-SJC\-/){c="SJC";}\
#          else if($4 ~ /\-OHC\-/){c="OHC";}\
#          else if($4 ~ /\-DB\-/){c="DB";}\
#          else if($4 ~ /\_CC\_/){c="CC";}\
#          printf("%s\t%s\t%s\n",$0,"giv3",c);}' > ${barcode_file_name}



# 454 sff data merging, deconvolution, trimming, and non-redundant filtering
# copy the 454 sff data
foreach sff_file (`echo ${sff_file_list} | tr -d ' ' | tr ',' '\n' | sort -u`)
  cp ${sff_file} ${sff_dir}/${sff_file:t}
end

# merge the 454 sff data
sfffile -o ${merged_sff_file} ${sff_dir}/*.sff

# deconvolve and trim the 454 sff data
nohup /usr/local/devel/ANNOTATION/naxelrod/VHTNGS/bin/barcode_deconvolver.pl \
  --barcode ${barcode_file_name} \
  --sff ${merged_sff_file} \
  --tmpdir ${merged_sff_file}_deconvolver_tmp \
  --outdir ${merged_sff_file}_deconvolver_test \
  --keylength 4 \
  --trimpoints >& ${merged_sff_file}_deconvolver.log
# Now wait until this is finished...  takes a while...  Be sure to check log file(s)

more  ${merged_sff_file}_deconvolver.log 

# If any exits due to errors occurred, you will need to re-run the command...

# use the barcode deconvolver output to bin and trim the sff data
foreach bc ( `cat ${barcode_file_name} | cut -f 1`)
  if ( -e ${merged_sff_file}_deconvolver_test/trim_${bc}.txt ) then
    echo "INFO: Processing SISPA pool [${sispa_pool_name}] 454 sff data for barcode [${bc}]"
    cut -f 2-4  ${merged_sff_file}_deconvolver_test/trim_${bc}.txt > \
      ${merged_sff_file}_deconvolver_test/trim_${bc}.txt.trim
    sfffile -o ${deconvolved_merged_sff_dir}/trim_${bc}.sff \
      -i ${merged_sff_file}_deconvolver_test/trim_${bc}.txt.trim \
      -t ${merged_sff_file}_deconvolver_test/trim_${bc}.txt.trim \
      ${merged_sff_file}
  endif
end

################################### SOLEXA DATA PROCESSING ####################################

# Solexa fastq data merging, deconvolution, trimming, and non-redundant filtering
foreach fastq_file (`echo ${fastq_file_list} | tr -d ' ' | tr ',' '\n' | sort -u`)
  cp ${fastq_file} ${fastq_dir}/${fastq_file:t}
end
# merge the fastq data
cat ${fastq_dir}/*_sequence.txt > ${merged_fastq_file}

# count the number of solexa records
set sol_rec_cnt = `grep "^@" ${merged_fastq_file} | wc -l`
echo "INFO: Solexa record count is [${sol_rec_cnt}]"

# calculate the number of partitions needed for solexa fastq data
if ( ${sol_rec_cnt} > 0 ) then
  @ num_parts = 1 + ${sol_rec_cnt} / ${max_sol_recs_per_deconv}
else
  @ num_parts = 0
endif
echo "INFO: Solexa partition count is [${num_parts}]"

# split solexa fastq file into fastq partition files
@ part = 0
while ( ${part} < ${num_parts} )
  echo "INFO: Building solexa fastq file partition [${part}] of [${num_parts}]"
  cat ${merged_fastq_file} | \
    gawk -v p=${part} -v t=${num_parts} \
      'BEGIN {rec_cnt=0; outflag=0;} \
       {if($0 ~ /^@/){rec_cnt+=1; if((rec_cnt % t) == p ){outflag=1;}else{outflag=0;}} \
        if(outflag==1){print $0;}}' > ${merged_fastq_file}.part_${part}
  @ part = ${part} + 1
end

# deconvolve and trim the solexa data using the barcode data
@ part = 0
while ( ${part} < ${num_parts} )
  echo "INFO: Deconvolving solexa fastq file partition [${part}] of [${num_parts}]"
  nohup /usr/local/devel/ANNOTATION/naxelrod/VHTNGS/bin/barcode_deconvolver.pl \
    --barcode ${barcode_file_name} \
    --fastq ${merged_fastq_file}.part_${part} \
    --tmpdir ${merged_fastq_file}_deconvolver_tmp.part_${part} \
    --outdir ${merged_fastq_file}_deconvolver_test.part_${part} \
    --trim \
    --outformat fastq \
    --mismatches 2 \
    --readlength 50 \
    --clamplength 6 \
    --keylength 0 \
    >& ${merged_fastq_file}_deconvolver.log.part_${part}
  @ part = ${part} + 1
end
# Now wait until this is finished...  takes a while...  Be sure to check log file(s)

more ${merged_fastq_file}_deconvolver.log.part_*

# combine the individual partitions of deconvolved and trimmed solexa data by barcode
# and then make the data non-redundant
foreach bc ( `cat ${barcode_file_name} | cut -f 1`)
  set deconvolved_fastq = ${deconvolved_merged_fastq_dir}/trim_${bc}.fastq
  if ( -e ${deconvolved_fastq} ) then
    rm ${deconvolved_fastq}
  endif
  touch ${deconvolved_fastq}
  @ part = 0
  while ( ${part} < ${num_parts} )
    echo "INFO: Combining solexa fastq file partition [${part}] of [${num_parts}] for barcode [${bc}]"
    if ( -e ${merged_fastq_file}_deconvolver_test.part_${part}/${bc}*.fastq ) then
      cat ${merged_fastq_file}_deconvolver_test.part_${part}/${bc}*.fastq >> ${deconvolved_fastq}
    else
      echo "WARNING:  [${merged_fastq_file}_deconvolver_test.part_${part}/${bc}*.fastq] does not exist"
    endif
    @ part = ${part} + 1
  end
  set nr_deconvolved_fastq = ${deconvolved_merged_fastq_dir}/nr_trim_${bc}.fastq
  cat ${deconvolved_fastq} | \
  gawk '{t=NR % 4;\
         if(t==1){\
           if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", s,sid,qid,q)};\
           sid=$0;\
         }\
         else if (t==2){s=$0;}\
         else if (t==3){qid=$0;}\
         else if (t==0){q=$0;}\
        }\
        END {\
          if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", s,sid,qid,q)};\
          sid=$0;\
        }' | \
  sort | \
  gawk -F'\t' '{if($1!=last && index($1,"N")==0){print $0;last=$1}}'  | \
  sort --key=2,2 -i | \
  gawk -F'\t' '{printf("%s\t%s\t%s\t%s\n", $2, $1, $3, $4);}' | \
  sort --key=1,1 -i | \
  gawk -F'\t' '{printf("%s\n%s\n%s\n%s\n", $1, $2, $3, $4);}' > ${nr_deconvolved_fastq}
end

############################# END SOLEXA DATA PROCESSING ###############################

############################# COPY SISPA DATA TO SAMPLE AREAS ##########################
foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' | grep gcv` )
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`
  echo "INFO: processing data for SISPA pool [${sispa_pool_name}] barcode [${bc}]"
  set nr_deconvolved_fastq = ${deconvolved_merged_fastq_dir}/nr_trim_${bc}.fastq
  set deconvolved_sff = ${deconvolved_merged_sff_dir}/trim_${bc}.sff
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}
  if ( -d ${sample_data} ) then
  else
    mkdir -p ${sample_data}
  endif
  set sample_data_solexa = ${sample_data}/solexa
  if ( -d ${sample_data_solexa} ) then
  else
    mkdir -p ${sample_data_solexa}
  endif
  set sample_data_sff = ${sample_data}/sff
  if ( -d ${sample_data_sff} ) then
  else
    mkdir -p ${sample_data_sff}
  endif
  if ( -e ${nr_deconvolved_fastq} ) then
    echo "INFO: copying fastq data to [${db_name}/${col_name}/${bac_id}]"
    cp ${nr_deconvolved_fastq} ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq
  endif
  if ( -e ${deconvolved_sff} ) then
    echo "INFO: copying sff data to [${db_name}/${col_name}/${bac_id}]"
    cp ${deconvolved_sff} ${sample_data_sff}/${sispa_pool_name}_trim_${bc}.sff
  endif
end

########################## CONSOLIDATE SAMPLE DATA ##################################
csh
set sispa_pool_name = 20090205_HIsamples6to100
set sispa_pool_name = 20090205_34xDW_5xHI_2xUNKNOWN_samples
set sispa_pool_name = 20090901_20xDW09_3xCC_12xSW_samples
set sispa_pool_name = 20091005_AVIAN113
set sispa_pool_name = 20091215_MCEIRSsamples1to50

set project_root = /usr/local/projects/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sample_data_root = ${project_root}/sample_data
set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt


foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' `)
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`
  echo "INFO: processing data for [${db_name}/${col_name}/${bac_id}]"
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}
  set sample_data_solexa = ${sample_data}/solexa
  set sample_data_sff = ${sample_data}/sff
  set sample_data_sanger = ${sample_data}/sanger
  if ( -d ${sample_data_sanger} ) then
  else
    mkdir -p ${sample_data_sanger}
  endif
  set sample_mapping_dir = ${sample_data}/mapping
  set final_fasta_reads = ${sample_mapping_dir}/${db_name}_${col_name}_${bac_id}_final.fasta
  if ( -e ${final_fasta_reads} ) then
    cp ${final_fasta_reads} ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta
  else
    echo "WARNING: No Sanger fasta file exists for [${db_name}/${col_name}/${bac_id}]"
    touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta
  endif

  set sample_data_merged_solexa = ${sample_data}/merged_solexa
  if ( -d ${sample_data_merged_solexa} ) then
  else
    mkdir -p ${sample_data_merged_solexa}
  endif
  set sample_data_merged_sff = ${sample_data}/merged_sff
  if ( -d ${sample_data_merged_sff} ) then
  else
    mkdir -p ${sample_data_merged_sff}
  endif
  set sample_data_merged_sanger = ${sample_data}/merged_sanger
  if ( -d ${sample_data_merged_sanger} ) then
  else
    mkdir -p ${sample_data_merged_sanger}
  endif
  set sample_data_merged_solexa_file = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq
  set sample_data_merged_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}.sff
  set sample_data_merged_sanger_file = ${sample_data_merged_sanger}/${db_name}_${col_name}_${bac_id}.fasta
  cat ${sample_data_solexa}/*_nr_trim_*.fastq > \
    ${sample_data_merged_solexa_file}
  sfffile -o ${sample_data_merged_sff_file} \
    ${sample_data_sff}/*_trim_*.sff
  cp ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta ${sample_data_merged_sanger_file}
end

################### THIS IS THE START OF VIRUS SPECIFIC HANDLING ###############
csh
setenv PATH /usr/local/packages/clc-ngs-cell-2.0.5-linux_64:/usr/local/packages/clc-bfx-cell:${PATH}
setenv RUBYLIB /usr/local/devel/DAS/users/eventer/svn/16s/site_analysis/Tools/Bio

set sispa_pool_name = 20090205_HIsamples6to100
set sispa_pool_name = 20090205_34xDW_5xHI_2xUNKNOWN_samples
set sispa_pool_name = 20090901_20xDW09_3xCC_12xSW_samples
set sispa_pool_name = 20091005_AVIAN113
set sispa_pool_name = 20091215_MCEIRSsamples1to50

set project_root = /usr/local/projects/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sample_data_root = ${project_root}/sample_data
set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt


# under ref_dir, look for <seg>.fasta
# under blast_db_dir, look for <seg>_full_length_NT_complete.fa, must have been run through formatdb!
# seg_cov is the segment followed by bps in 100x coverage
# for unsegmented viruses, use MAIN as segment name

foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' ` )
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`

  switch ($db_name)
    case giv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/GIV/Influenza_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
    breaksw
    case giv3:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/GIV/Influenza_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
    breaksw
    case piv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/GIV/Influenza_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
    breaksw
    case swiv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/GIV/Influenza_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
    breaksw
    case gcv:
      echo "Using Coronavirus reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/corona_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/corona_virus_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:3000000"
    breaksw
  endsw

  echo "INFO: processing data for [${db_name}/${col_name}/${bac_id}]"
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}
  set sample_data_merged_solexa = ${sample_data}/merged_solexa
  set sample_data_merged_sff = ${sample_data}/merged_sff
  set sample_data_merged_sanger = ${sample_data}/merged_sanger
  set sample_data_merged_solexa_file = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq
  set sample_data_merged_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}.sff
  set sample_data_merged_sanger_file = ${sample_data_merged_sanger}/${db_name}_${col_name}_${bac_id}.fasta

  if ( -e ${sample_data_merged_solexa_file}.fasta ) then
    rm ${sample_data_merged_solexa_file}.fasta
  endif
  touch ${sample_data_merged_solexa_file}.fasta

  if ( -e ${sample_data_merged_solexa_file}.fasta.qual ) then
    rm ${sample_data_merged_solexa_file}.fasta.qual
  endif
  touch ${sample_data_merged_solexa_file}.fasta.qual

  if ( `cat ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
    echo "INFO: converting fastq to fasta for [${db_name}/${col_name}/${bac_id}]"
    if ( -e convert.fa ) then
      rm convert.fa
    endif
    if ( -e convert.qual ) then
      rm convert.qual
    endif
    /usr/local/devel/DAS/users/eventer/svn/16s/site_analysis/Tools/Bio/fastq2seqQualFasta.rb \
      convert \
      ${sample_data_merged_solexa_file}
    cat convert.fa | tr '@' '>' > ${sample_data_merged_solexa_file}.fasta
    cat convert.qual | tr '@' '>' > ${sample_data_merged_solexa_file}.fasta.qual
    rm convert.fa
    rm convert.qual
  endif

  echo "INFO: converting sff to fasta for [${db_name}/${col_name}/${bac_id}]"
  sffinfo -s ${sample_data_merged_sff_file} | \
    grep -v " length=0 " \
    > ${sample_data_merged_sff_file}.fna

  if ( `cat ${sample_data_merged_sff_file}.fna | wc -l` > 0 ) then
    echo "INFO: formatdb of SFF fasta for [${db_name}/${col_name}/${bac_id}]"
    formatdb -p F -i ${sample_data_merged_sff_file}.fna
  endif

  if ( `cat ${sample_data_merged_sanger_file} | wc -l` > 0 ) then
    echo "INFO: formatdb of Sanger fasta for [${db_name}/${col_name}/${bac_id}]"
    formatdb -p F -i ${sample_data_merged_sanger_file}
  endif

  set tblastx_outdir = ${sample_data}/tblastx_output
  if ( -d ${tblastx_outdir} ) then
  else
    mkdir -p ${tblastx_outdir}
  endif

  foreach seg ( `echo ${segments} | tr ' ' '\n' ` )
    echo "INFO: tblastx segment data [${seg}] against SFF and Sanger reads databases for [${db_name}/${col_name}/${bac_id}]"
    set ref_fna = ${ref_dir}/${seg}.fasta

    if ( `cat ${sample_data_merged_sff_file}.fna | wc -l` > 0 ) then
      set blastdb = ${sample_data_merged_sff_file}.fna
      set blastout = ${tblastx_outdir}/${seg}.out
      blastall \
        -p tblastx \
        -d ${blastdb} \
        -i ${ref_fna} \
        -m 9 \
        -b 100000 \
        -v 100000 \
        -o ${blastout}
    else
      touch ${blastout}
    endif

    if ( `cat ${sample_data_merged_sanger_file} | wc -l` > 0 ) then
      set blastdb = ${sample_data_merged_sanger_file}
      set blastout = ${tblastx_outdir}/${seg}_sanger.out
      blastall \
        -p tblastx \
        -d ${blastdb} \
        -i ${ref_fna} \
        -m 9 \
        -b 100000 \
        -v 100000 \
        -o ${blastout}
    else
      touch ${blastout}
    endif
  end

  set noninter_chimera_list = ${tblastx_outdir}/noninter_chimera_reads.uaccno_list
  set inter_chimera_list = ${tblastx_outdir}/inter_chimera_reads.uaccno_list
  foreach seg ( `echo ${segments} | tr ' ' '\n' ` )
    echo "INFO: parsing tblastx output for segment [${seg}] against [${db_name}/${col_name}/${bac_id}]"
    set blastout = ${tblastx_outdir}/${seg}.out
    set blastout_sanger = ${tblastx_outdir}/${seg}_sanger.out
    set nonintra_chimera_list = ${tblastx_outdir}/${seg}_nonintra_chimera_reads.uaccno_list
    set intra_chimera_list = ${tblastx_outdir}/${seg}_intra_chimera_reads.uaccno_list
    cat ${blastout} ${blastout_sanger} | \
      gawk '{if($0 !~ "#" && $3>60 && $4 > 25 ) {if(($7-$8)*($9-$10)>0){o=1;d=$8-$10;}else{o=0;d=$8+$10;}{printf("%s\t%s\t%s\t%06d\n",$1,$2, o,d);}}}' | \
      sort -g | \
      uniq | \
      gawk '{if( $1==q && $2==s && $3==o && sqrt(($4-d)^2) < 6){d=$4;}else {print $0;q=$1;s=$2;o=$3;d=$4;}}' | \
      cut -f 1,2 | \
      uniq -c | \
      grep " 1 " | \
      gawk '{print $3}' | \
      sort | \
      uniq > ${nonintra_chimera_list}
    cat ${blastout} ${blastout_sanger} | \
      gawk '{if($0 !~ "#" && $3>60 && $4 > 25 ) {if(($7-$8)*($9-$10)>0){o=1;d=$8-$10;}else{o=0;d=$8+$10;}{printf("%s\t%s\t%s\t%06d\n",$1,$2, o,d);}}}' | \
      sort -g | \
      uniq | \
      gawk '{if( $1==q && $2==s && $3==o && sqrt(($4-d)^2) < 6){d=$4;}else {print $0;q=$1;s=$2;o=$3;d=$4;}}' | \
      cut -f 1,2 | \
      uniq -c | \
      grep -v " 1 " | \
      gawk '{print $3}' | \
      sort | \
      uniq > ${intra_chimera_list}
  end
  cat ${tblastx_outdir}/*_nonintra_chimera_reads.uaccno_list | \
    sort | \
    uniq -c | \
    tr '\t' ' ' | \
    grep " 1 " | \
    gawk '{print $2}' > ${noninter_chimera_list}
  cat ${tblastx_outdir}/*_nonintra_chimera_reads.uaccno_list | \
    sort | \
    uniq -c | \
    tr '\t' ' ' | \
    grep -v " 1 " | \
    gawk '{print $2}' > ${inter_chimera_list}

  foreach seg ( `echo ${segments} | tr ' ' '\n' ` )
    set nonintra_chimera_list = ${tblastx_outdir}/${seg}_nonintra_chimera_reads.uaccno_list
    set non_chimera_list = ${tblastx_outdir}/${seg}_nonchimera_reads.uaccno_list
    join -1 1 -2 1 \
      ${noninter_chimera_list} \
      ${nonintra_chimera_list} > \
      ${non_chimera_list}
    echo "INFO: creating sff of non_chimeric reads from reads matching segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
    set sample_seg_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}_nonchimera_${seg}.sff
    sfffile \
      -i ${non_chimera_list} \
      -o ${sample_seg_sff_file} \
      ${sample_data_merged_sff_file}

    if ( `cat ${sample_data_merged_sanger_file} | wc -l` > 0 ) then
      echo "INFO: creating Sanger fasta of non_chimeric reads from reads matching segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
      set sample_seg_sanger_file = ${sample_data_merged_sanger}/${db_name}_${col_name}_${bac_id}_nonchimera_${seg}.fasta
      fnafile \
        -i ${non_chimera_list} \
        -o ${sample_seg_sanger_file} \
        ${sample_data_merged_sanger_file}
    endif

    echo "INFO: creating 100x max coverage sff of non_chimeric reads from reads matching segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
    set bps = `echo ${seg_cov} | tr ' ' '\n' | grep ${seg} | cut -d ':' -f 2`
    set sample_seg_100x_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.sff
    sfffile \
      -pick ${bps} \
      -o ${sample_seg_100x_sff_file} \
      ${sample_seg_sff_file}

    set seg_assembly_dir = ${sample_data}/assembly_by_segment/${seg}
    if ( -d ${seg_assembly_dir} ) then
    else
      mkdir -p ${seg_assembly_dir}
    endif

    pushd ${seg_assembly_dir} >& /dev/null
      echo "INFO: performing de novo assembly of 100x coverage for nonchimera reads from segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"

      ln -s /usr/local/packages/clc-bfx-cell/license.properties ./
      if ( `cat ${sample_seg_sanger_file} | wc -l` > 0 ) then
        clc_novo_assemble \
          -o ${seg}_100x_contigs.fasta \
          -q ${sample_seg_100x_sff_file} \
          -q ${sample_seg_sanger_file} \
          >& ${seg}_100x_clc_novo_assemble.log
      else
        clc_novo_assemble \
          -o ${seg}_100x_contigs.fasta \
          -q ${sample_seg_100x_sff_file} \
          >& ${seg}_100x_clc_novo_assemble.log
      endif

      set contig_cnt = `grep "^>" ${seg}_100x_contigs.fasta | wc -l`
      if ( ${contig_cnt} < 1 ) then
        echo "WARNING: clc de novo assembly of 100x coverage failed, trying cap3 for nonchimera reads from segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
        sffinfo \
          -s ${sample_seg_100x_sff_file} | \
          grep -v " length=0 " \
          > ${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.fasta

        if ( `cat ${sample_seg_sanger_file} | wc -l` > 0 ) then
          cat ${sample_seg_sanger_file} >> ${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.fasta
        endif

        cap3 ${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.fasta
        mv ${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.fasta.cap.contigs ${seg}_100x_contigs.fasta
        rm ${db_name}_${col_name}_${bac_id}_nonchimera_${seg}_100x.fasta*
      endif
      
      set blast_db = ${blast_db_dir}/${seg}_full_length_NT_complete.fa
      set best_reference = ${seg_assembly_dir}/${seg}_best_reference.fna
      if ( -e ${seg}_100x_contigs.fasta ) then
        echo "INFO: finding best FL reference for segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
        set best_hit = \
          `blastall \
             -p blastn \
             -d ${blast_db} \
             -b 1 \
             -v 1 \
             -m 8 \
             -i ${seg}_100x_contigs.fasta | \
          sort -nrk12 | \
          head -n 1 | \
          gawk '{printf("%s\n", $2);}'`
        fastacmd -d ${blast_db} -p F -s "${best_hit}"  -o ${best_reference}
        grep "^>" ${best_reference} | cut -c 2- | gawk -v s=${seg} '{printf(">%s %s\n", s, $0);}' > ${best_reference}_mod
        grep -v "^>" ${best_reference} >> ${best_reference}_mod
        mv ${best_reference}_mod ${best_reference}
      else
        echo "ERROR: missing de novo assembly of 100x coverage for nonchimera reads from segment [${seg}] for [${db_name}/${col_name}/${bac_id}]"
      endif
    popd >& /dev/null
  end

  echo "INFO: consolidating best FL reference flu sequences for [${db_name}/${col_name}/${bac_id}]"
  set seg_best_ref_dir = ${sample_data}/reference_fasta
  if ( -d ${seg_best_ref_dir} ) then
  else
    mkdir -p ${seg_best_ref_dir}
  endif
  set best_refs_file = ${seg_best_ref_dir}/reference.fasta
  cat ${sample_data}/assembly_by_segment/*/*_best_reference.fna > ${best_refs_file}

  echo "INFO: consolidating nonchimera 454 reads for [${db_name}/${col_name}/${bac_id}]"
  set non_chimera_list = ${tblastx_outdir}/nonchimera_reads.uaccno_list
  cat ${tblastx_outdir}/*_nonchimera_reads.uaccno_list > ${non_chimera_list}
  set deconvolved_sff = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}_nonchimera.sff
  sfffile -i ${non_chimera_list} \
    -o ${deconvolved_sff} \
    ${sample_data_merged_sff_file}

  echo "INFO: mapping flu sequences for [${db_name}/${col_name}/${bac_id}]"
  set sample_mapping_dir = ${sample_data}/mapping
  if ( -d ${sample_mapping_dir} ) then
  else
    mkdir -p ${sample_mapping_dir}
  endif

  pushd ${sample_mapping_dir} >& /dev/null
    ln -s /usr/local/packages/clc-bfx-cell/license.properties ./

    echo "INFO: using clc_ref_assemble_long to find sff SNPs for [${db_name}_${col_name}_${bac_id}]"
    clc_ref_assemble_long \
      -s 0.95 \
      -o ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.cas \
      -q ${deconvolved_sff} \
      -d ${best_refs_file}
    find_variations \
      -a ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.cas \
      -c 2 \
      -o ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.new_contigs \
      -v \
      -f 0.2 >& ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log
    cat ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log | \
      grep -v Nochange | \
      cut -d ':' -f 1 | \
      gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
             else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
      ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced

    touch ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced
    if ( `cat ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
      echo "INFO: using clc_ref_assemble_long to find fastq SNPs for [${db_name}_${col_name}_${bac_id}]"
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.cas \
        -q ${sample_data_merged_solexa_file} \
        -d ${best_refs_file}
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
        ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced
    endif

    if ( `cat ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced | wc -l` > 0 ) then
      comm -12 \
        ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced \
        ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced > \
        ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced
    else
      cp \
        ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced \
        ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced
    endif 

    echo "INFO: building edited references based on common sff and fastq SNPs for [${db_name}_${col_name}_${bac_id}]"
    foreach seg ( `grep "^>" ${best_refs_file} | cut -d ' ' -f 1 | cut -c 2-` )
      nthseq -sequence ${best_refs_file} \
        -number `grep "^>" ${best_refs_file} | cut -d ' ' -f 1 | cut -c 2- | grep -n ${seg} | cut -d ':' -f 1` \
        -outseq ${db_name}_${col_name}_${bac_id}_${seg}.extracted >& /dev/null
      cat ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced | \
        grep ${seg} | \
        cut -d ':' -f 2-3 | \
        tr '\n ' ' ' > ${db_name}_${col_name}_${bac_id}_${seg}.edits
      /usr/local/devel/DAS/software/resequencing/prod/data_analysis/delta2seq.pl \
        -r ${db_name}_${col_name}_${bac_id}_${seg}.extracted \
        -f ${db_name}_${col_name}_${bac_id}_${seg}.edits \
        -q ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited
      grep "^>" ${db_name}_${col_name}_${bac_id}_${seg}.extracted > \
        ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited.fasta
      grep -v "^>" ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited >> \
        ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited.fasta
    end
    set best_edited_refs_file = ${db_name}_${col_name}_${bac_id}_reference_edited.fasta
    cat ${db_name}_${col_name}_${bac_id}_*.extracted.edited.fasta > \
      ${best_edited_refs_file}

    echo "INFO: using 454 mapper for final chimera check for [${db_name}_${col_name}_${bac_id}]"

    newMapping 454_mapping_best_refs_chimera_check
    setRef 454_mapping_best_refs_chimera_check ${best_edited_refs_file}
    addRun 454_mapping_best_refs_chimera_check ${deconvolved_sff}
    if ( `cat ${sample_data_merged_solexa_file}.fasta | wc -l` > 0 ) then
      addRun 454_mapping_best_refs_chimera_check ${sample_data_merged_solexa_file}.fasta
    endif
    runProject -no 454_mapping_best_refs_chimera_check >& runProject_454_mapping_best_refs_chimera_check.log
    grep "Chimeric" 454_mapping_best_refs_chimera_check/mapping/454ReadStatus.txt | \
      gawk '{print $1}' > exclude_list.txt
    set final_sff_reads = ${db_name}_${col_name}_${bac_id}_final.sff
    set final_fastq_reads = ${db_name}_${col_name}_${bac_id}_final.fastq
    set final_fasta_reads = ${db_name}_${col_name}_${bac_id}_final.fasta

    sfffile \
      -o ${final_sff_reads} \
      -e exclude_list.txt \
      ${deconvolved_sff}

    touch ${final_fastq_reads}
    if ( `cat ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
      /usr/local/devel/DAS/software/JavaCommon2/fastQfile.pl \
        -o ${final_fastq_reads} \
        -e exclude_list.txt \
        ${sample_data_merged_solexa_file}
    endif

    echo "INFO: running clc_ref_assemble_long for [${db_name}_${col_name}_${bac_id}]"

    if ( `cat ${final_fasta_reads} | wc -l` > 0 ) then
      if ( `cat ${final_fastq_reads} | wc -l` > 0 ) then
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
          -q ${final_sff_reads} \
          -q ${final_fastq_reads} \
          -q ${final_fasta_reads} \
          -d ${best_edited_refs_file}
      else
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
          -q ${final_sff_reads} \
          -q ${final_fasta_reads} \
          -d ${best_edited_refs_file}
      endif
    else
      if ( `cat ${final_fastq_reads} | wc -l` > 0 ) then
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
          -q ${final_sff_reads} \
          -q ${final_fastq_reads} \
          -d ${best_edited_refs_file}
      else
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
          -q ${final_sff_reads} \
          -d ${best_edited_refs_file}
      endif
    endif

    find_variations \
      -a ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
      -c 2 \
      -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs \
      -v \
      -f 0.2 >& ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs_find_variations.log

    echo "INFO: running fluValidator for [${db_name}_${col_name}_${bac_id}]"
    /usr/local/devel/DAS/software/ElviraStaging/bin/fluValidator \
      --fasta ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs > \
      ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs.fluValidator 

  popd >& /dev/null
end


################### QUICKLY BUILD SANGER_ONLY VARIATIONS FILE ###############
csh
setenv PATH /usr/local/packages/clc-ngs-cell-2.0.5-linux_64:/usr/local/packages/clc-bfx-cell:${PATH}

set sispa_pool_name = 20090205_HIsamples6to100
set sispa_pool_name = 20090205_34xDW_5xHI_2xUNKNOWN_samples
set sispa_pool_name = 20090901_20xDW09_3xCC_12xSW_samples
set sispa_pool_name = 20091005_AVIAN113
set sispa_pool_name = 20091215_MCEIRSsamples1to50

set project_root = /usr/local/projects/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sample_data_root = ${project_root}/sample_data
set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt

foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' ` )
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`

  echo "INFO: processing data for [${db_name}/${col_name}/${bac_id}]"
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}

  set sample_mapping_dir = ${sample_data}/mapping
  if ( -d ${sample_mapping_dir} ) then
  else
    mkdir -p ${sample_mapping_dir}
  endif

  pushd ${sample_mapping_dir} >& /dev/null
    ln -s /usr/local/packages/clc-bfx-cell/license.properties ./

    set best_edited_refs_file = ${db_name}_${col_name}_${bac_id}_reference_edited.fasta
    set final_fasta_reads = ${db_name}_${col_name}_${bac_id}_final.fasta

    if ( -e ${final_fasta_reads} ) then
      if ( `cat ${final_fasta_reads} | wc -l` > 0 ) then
        echo "INFO: using clc_ref_assemble_long to find SANGER SNPs for [${db_name}_${col_name}_${bac_id}]"
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.cas \
          -q ${final_fasta_reads} \
          -d ${best_edited_refs_file}
        find_variations \
          -a ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.cas \
          -c 2 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.new_contigs \
          -v \
          -f 0.2 >& ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs_find_variations.log
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.cas \
          -q ${final_fasta_reads} \
          -d consed_with_sanger/cas2consed.consensus.fasta
        find_variations \
          -a ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.cas \
          -c 2 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.new_contigs \
          -v \
          -f 0.2 >& ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed_find_variations.log
      endif
    endif
  popd >& /dev/null
end

################### QUICKLY BUILD 454_ONLY, SOLEXA_ONLY, and SANGER_ONLY VARIATIONS FILE ###############
csh
setenv PATH /usr/local/packages/clc-ngs-cell-2.0.5-linux_64:/usr/local/packages/clc-bfx-cell:${PATH}

set sispa_pool_name = 20090205_HIsamples6to100
set sispa_pool_name = 20090205_34xDW_5xHI_2xUNKNOWN_samples
set sispa_pool_name = 20090901_20xDW09_3xCC_12xSW_samples
set sispa_pool_name = 20091005_AVIAN113
set sispa_pool_name = 20091215_MCEIRSsamples1to50

set project_root = /usr/local/projects/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sample_data_root = ${project_root}/sample_data
set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt

foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' ` )
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`

  echo "INFO: processing data for [${db_name}/${col_name}/${bac_id}]"
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}

  set sample_mapping_dir = ${sample_data}/mapping
  if ( -d ${sample_mapping_dir} ) then
  else
    mkdir -p ${sample_mapping_dir}
  endif

  pushd ${sample_mapping_dir} >& /dev/null
    ln -s /usr/local/packages/clc-bfx-cell/license.properties ./

    set best_edited_refs_file = ${db_name}_${col_name}_${bac_id}_reference_edited.fasta
    set final_sff_reads = ${db_name}_${col_name}_${bac_id}_final.sff
    set final_fastq_reads = ${db_name}_${col_name}_${bac_id}_final.fastq
    set final_fasta_reads = ${db_name}_${col_name}_${bac_id}_final.fasta

    if ( -e ${final_sff_reads} ) then
      echo "INFO: using clc_ref_assemble_long to find 454 SNPs for [${db_name}_${col_name}_${bac_id}]"
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_edited_refs.cas \
        -q ${final_sff_reads} \
        -d ${best_edited_refs_file}
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_454_only_edited_refs.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_edited_refs.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_454_only_edited_refs_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_454_only_edited_refs_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_454_only_edited_refs_find_variations.log.reduced
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_cas2consed.cas \
        -q ${final_sff_reads} \
        -d consed_with_sanger/cas2consed.consensus.fasta
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_454_only_cas2consed.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_cas2consed.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_454_only_cas2consed_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_454_only_cas2consed_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_454_only_cas2consed_find_variations.log.reduced
    endif

    if ( -e ${final_fastq_reads} ) then
      echo "INFO: using clc_ref_assemble_long to find SOLEXA SNPs for [${db_name}_${col_name}_${bac_id}]"
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs.cas \
        -q ${final_fastq_reads} \
        -d ${best_edited_refs_file}
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_solexa_only_edited_refs_find_variations.log.reduced
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed.cas \
        -q ${final_fastq_reads} \
        -d consed_with_sanger/cas2consed.consensus.fasta
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_solexa_only_cas2consed_find_variations.log.reduced
    endif

    if ( -e ${final_fasta_reads} ) then
      if ( `cat ${final_fasta_reads} | wc -l` > 0 ) then
        echo "INFO: using clc_ref_assemble_long to find SANGER SNPs for [${db_name}_${col_name}_${bac_id}]"
        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.cas \
          -q ${final_fasta_reads} \
          -d ${best_edited_refs_file}
        find_variations \
          -a ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.cas \
          -c 2 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs.new_contigs \
          -v \
          -f 0.2 >& ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs_find_variations.log | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_sanger_only_edited_refs_find_variations.log.reduced

        clc_ref_assemble_long \
          -s 0.95 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.cas \
          -q ${final_fasta_reads} \
          -d consed_with_sanger/cas2consed.consensus.fasta
        find_variations \
          -a ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.cas \
          -c 2 \
          -o ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed.new_contigs \
          -v \
          -f 0.2 >& ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed_find_variations.log | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
          ${db_name}_${col_name}_${bac_id}_sanger_only_cas2consed_find_variations.log.reduced
      endif
    endif
  popd >& /dev/null
end









