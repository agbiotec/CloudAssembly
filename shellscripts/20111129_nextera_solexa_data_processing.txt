csh
set term = xterm-color
use sge
source /usr/local/sge_current/jcvi/common/settings.csh
setenv PATH /usr/local/packages/seq454-2.6/bin:${PATH}
setenv PATH /usr/local/packages/clc-ngs-cell:/usr/local/packages/clc-bfx-cell:${PATH}
setenv RUBYLIB /usr/local/devel/DAS/users/tstockwe/Ruby/Tools/Bio
use emboss50
umask 002

set sispa_pool_name = N20110926_38xMDVERO
set sff_file_list = "\
"
set fastq_file_pattern = "\
/usr/local/JTC/data/SOLEXA_archive1/111115_SOLEXA4_0085_AC06AFACXX/Unaligned_21-11-2011/Project_coronavirusillumina/Sample_N20110926-PE-1/N20110926-PE-1_BARCODESEQUENCE_L002_R1_filtered.fastq \
"

set project_root = /usr/local/projects/VHTNGS
set scratch_root = /usr/local/scratch/VIRAL/VHTNGS
set barcode_data_root = ${project_root}/barcode_data
set sispa_data_root = ${project_root}/sispa_data_new
set sispa_data_root = ${scratch_root}/sispa_data_new
set sample_data_root = ${project_root}/sample_data_new
set barcode_data_dir = ${barcode_data_root}/${sispa_pool_name}
set sispa_data_dir = ${sispa_data_root}/${sispa_pool_name}
set fastq_dir = ${sispa_data_dir}/fastq
set merged_fastq_dir = ${sispa_data_dir}/merged_fastq
set deconvolved_merged_fastq_dir = ${sispa_data_dir}/deconvolved_merged_fastq
set sff_dir = ${sispa_data_dir}/sff
set merged_sff_dir = ${sispa_data_dir}/merged_sff
set deconvolved_merged_sff_dir = ${sispa_data_dir}/deconvolved_merged_sff
set merged_fastq_file = ${merged_fastq_dir}/merged_solexa_sequence.fastq
set merged_sff_file = ${merged_sff_dir}/merged_454.sff
set barcode_file_name = ${barcode_data_dir}/barcode_metadata_from_GLK.txt

mkdir -p ${scratch_root}

pushd ${project_root}

if ( -d ${barcode_data_root} ) then
else
  mkdir -p ${barcode_data_root}
endif
if ( -d ${sispa_data_root} ) then
else
  mkdir -p ${sispa_data_root}
endif
if ( -d ${sample_data_root} ) then
else
  mkdir -p ${sample_data_root}
endif

if ( -d ${barcode_data_dir} ) then
else
  mkdir -p ${barcode_data_dir}
endif
if ( -d ${sispa_data_dir} ) then
else
  mkdir -p ${sispa_data_dir}
endif


if ( -d ${fastq_dir} ) then
else
  mkdir -p ${fastq_dir}
endif
if ( -d ${merged_fastq_dir} ) then
else
  mkdir -p ${merged_fastq_dir}
endif
if ( -d ${deconvolved_merged_fastq_dir} ) then
else
  mkdir -p ${deconvolved_merged_fastq_dir}
endif


if ( -d ${sff_dir} ) then
else
  mkdir -p ${sff_dir}
endif
if ( -d ${merged_sff_dir} ) then
else
  mkdir -p ${merged_sff_dir}
endif
if ( -d ${deconvolved_merged_sff_dir} ) then
else
  mkdir -p ${deconvolved_merged_sff_dir}
endif

# build tab-separated-file of barcode metadata based on Excel file attached to 454 BugZero #???
# column order is:
# barcode_name, 
# barcode_sequence, 
# bac_id, 
# blinded_number, 
# species, 
# database_name, 
# collection_name,
# optional - sanger data exists? yes or no

kedit ${barcode_file_name}

if ( -e ${barcode_file_name}.pat ) then
  rm ${barcode_file_name}.pat
endif
touch ${barcode_file_name}.pat
cat ${barcode_file_name} | \
  gawk '{mm=int(length($2)/10.0); printf(">%s <mismatch=%d>\n%s\n", $1, mm, $2);}' \
  >> ${barcode_file_name}.pat

############################# COPY FASTQ NEXTERA DATA TO SAMPLE AREAS ##########################
##### MAY NEED TO MAKE fastq_file_pattern BE AN ITERATOR OVER A fastq_file_pattern_list ########

foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' ` )
  set bc       = `echo "${bc_rec}" | cut -d ':' -f 1`
  set bc_seq   = `echo "${bc_rec}" | cut -d ':' -f 2`
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 3`
  set blinded  = `echo "${bc_rec}" | cut -d ':' -f 4`
  set species  = `echo "${bc_rec}" | cut -d ':' -f 5`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 6`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 7`
  set bac_id_len = `echo ${bac_id} | tr -d '\n' | wc -c`
  set db_name_len = `echo ${db_name} | tr -d '\n' | wc -c`
  set col_name_len = `echo ${col_name} | tr -d '\n' | wc -c`
  if (${bac_id_len} > 0 && ${db_name_len} > 0 && ${col_name_len} > 0) then
    echo "INFO: processing FASTQ data for NEXTERA pool [${sispa_pool_name}] barcode [${bc}]"
    set nr_deconvolved_fastq = `echo ${fastq_file_pattern} | sed -e "s/BARCODESEQUENCE/${bc_seq}/g"`

    set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}

    set sample_data_solexa = ${sample_data}/solexa

    if ( -d ${sample_data} ) then
    else
      mkdir -p ${sample_data}
    endif

    if ( -d ${sample_data_solexa} ) then
    else
      mkdir -p ${sample_data_solexa}
    endif

    if ( -e ${nr_deconvolved_fastq} ) then
      echo "INFO: copying fastq data to [${db_name}/${col_name}/${bac_id}]"
      /home/tstockwe/bin/convert_to_old_illumina_fastq_header.sh ${nr_deconvolved_fastq} ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq.unsorted
      cat ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq.unsorted | \
        gawk '{t=NR % 4;\
               if(t==1){\
                 if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
                 sid=substr($0,2);\
               }\
               else if (t==2){s=$0;}\
               else if (t==3){qid=sid;}\
               else if (t==0){q=$0;}\
              }\
              END {\
                if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
              }' | \
        sort | \
        gawk -F'\t' '{printf("@%s\n%s\n+%s\n%s\n", $1, $2, "", $4);}' > ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq

      cp ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq ${sample_data_solexa}/${sispa_pool_name}_trim_${bc}.fastq.untrimmed
      cat ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq | \
        gawk '{t=NR % 4;\
             if(t==1){\
               if(length(sid) > 0 ) {printf("%s\t%d\t%d\n", sid,1,length(s))};\
               sid=substr($0,2);\
             }\
             else if (t==2){s=$0;}\
             else if (t==3){qid=sid;}\
             else if (t==0){q=$0;}\
            }\
            END {\
              if(length(sid) > 0 ) {printf("%s\t%d\t%d\n", sid,1,length(s))};\
            }' > ${sample_data_solexa}/${sispa_pool_name}_trim_${bc}.fastq.trimpoints

      rm ${sample_data_solexa}/${sispa_pool_name}_nr_trim_${bc}.fastq.unsorted
    endif

  else
    echo "WARNING:  No FASTQ sample data transfer for bc_rec [${bc_rec}]"
  endif
end

########################## CONSOLIDATE SEQUENCE DATA FOR SAMPLE ##################################

foreach bc_rec ( `cat ${barcode_file_name} | tr ' ' '_' | tr '\t' ':' | cut -d ':' -f 3,6,7 | sort -u | grep -v "POSCTRL"`)
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 1`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 2`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 3`

  echo "INFO: consolidating sequence data for sample [${db_name}/${col_name}/${bac_id}]"

  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}
  set sample_data_solexa = ${sample_data}/solexa
  set sample_data_sff = ${sample_data}/sff
  set sample_data_sanger = ${sample_data}/sanger
  set sample_mapping_dir = ${sample_data}/mapping
  set final_fasta_reads = ${sample_mapping_dir}/${db_name}_${col_name}_${bac_id}_final.fasta

  set sample_data_merged_solexa = ${sample_data}/merged_solexa
  set sample_data_merged_sff = ${sample_data}/merged_sff
  set sample_data_merged_sanger = ${sample_data}/merged_sanger

  set sample_data_merged_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}.sff
  set sample_data_merged_sanger_file = ${sample_data_merged_sanger}/${db_name}_${col_name}_${bac_id}.fasta
  set sample_data_merged_solexa_file = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq
  set sample_data_merged_solexa_file_t = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq.trimpoints
  set sample_data_merged_solexa_file_u = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq.untrimmed

  if ( -d ${sample_data_merged_sff} ) then
  else
    mkdir -p ${sample_data_merged_sff}
  endif

  if ( -d ${sample_data_merged_solexa} ) then
  else
    mkdir -p ${sample_data_merged_solexa}
  endif

  if ( -d ${sample_data_sanger} ) then
  else
    mkdir -p ${sample_data_sanger}
  endif

  if ( -d ${sample_data_merged_sanger} ) then
  else
    mkdir -p ${sample_data_merged_sanger}
  endif

  foreach key (`ls -1 ${sample_data_sff} | grep "\.[ACGT][ACGT][ACGT][ACGT]\." | cut -d '.' -f 2 | sort -u`)
    sfffile -o ${sample_data_merged_sff_file:r}.${key}.sff \
      ${sample_data_sff}/*_trim_*.${key}.sff
  end


  cat ${sample_data_solexa}/*_nr_trim_*.fastq | \
    gawk '{t=NR % 4;\
           if(t==1){\
             if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
             sid=substr($0,2);\
           }\
           else if (t==2){s=$0;}\
           else if (t==3){qid=sid;}\
           else if (t==0){q=$0;}\
          }\
          END {\
             if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
          }' | \
    sort | \
    gawk -F'\t' '{printf("@%s\n%s\n+%s\n%s\n", $1, $2, "", $4);}' \
      > ${sample_data_merged_solexa_file}

  cat ${sample_data_solexa}/*_trim_*.fastq.trimpoints | \
    sort \
    > ${sample_data_merged_solexa_file_t}

  cat ${sample_data_solexa}/*_trim_*.fastq.untrimmed | \
    gawk '{t=NR % 4;\
           if(t==1){\
             if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
             sid=substr($0,2);\
           }\
           else if (t==2){s=$0;}\
           else if (t==3){qid=sid;}\
           else if (t==0){q=$0;}\
          }\
          END {\
             if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,sid,q)};\
          }' | \
    sort | \
    gawk -F'\t' '{printf("@%s\n%s\n+%s\n%s\n", $1, $2, "", $4);}' \
      > ${sample_data_merged_solexa_file_u}

  if ( -e ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta ) then
    if ( `cat ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta | wc -l` > 0 ) then
    else
      echo "WARNING: No Sanger fasta file exists for [${db_name}/${col_name}/${bac_id}]"
      touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta
      touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.untrimmed
      touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimpoints
    endif
  else
    echo "WARNING: No Sanger fasta file exists for [${db_name}/${col_name}/${bac_id}]"
    touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta
    touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.untrimmed
    touch ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimpoints
  endif

  cat ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta | gawk '{if(length($0)>0){print;}}' > ${sample_data_merged_sanger_file}
  cat ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.untrimmed | gawk '{if(length($0)>0){print;}}' > ${sample_data_merged_sanger_file}.untrimmed
  if ( -e ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimPoints ) then
    if ( `cat ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimPoints | wc -l` > 0 ) then
      cp ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimPoints ${sample_data_merged_sanger_file}.trimpoints
    endif
  endif
  if ( -e ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimpoints ) then
    if ( `cat ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimpoints | wc -l` > 0 ) then
      cp ${sample_data_sanger}/${db_name}_${col_name}_${bac_id}_final.fasta.trimpoints ${sample_data_merged_sanger_file}.trimpoints
    endif
  endif

end

#################### COPY PI SPECIFIED REFERENCES TO SAMPLE AREAS BASED ON SAMPLE DESCRIPTIONS ##################

echo "gi|270309412|gb|FJ882938.1|" > include_270309412.txt
echo "gi|270309284|gb|FJ882930.1|" > include_270309284.txt

fnafile -o 270309412.fa -i include_270309412.txt /usr/local/projects/VHTNGS/reference_data/corona_virus_full_length_NT/MAIN_full_length_NT_complete.fa
fnafile -o 270309284.fa -i include_270309284.txt /usr/local/projects/VHTNGS/reference_data/corona_virus_full_length_NT/MAIN_full_length_NT_complete.fa

set key_ref_list = "WTic:270309412,ExoN1:270309284"

foreach key_ref ( `echo ${key_ref_list} | tr ',' '\n'` )
  set key = `echo "${key_ref}" | cut -d ':' -f 1`
  set ref = `echo "${key_ref}" | cut -d ':' -f 2`

  foreach bc_rec ( `cat ${barcode_file_name} | grep "${key}" | tr ' ' '_' | tr '\t' ':' | cut -d ':' -f 3,6,7 | sort -u | grep -v "POSCTRL"`)
    set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 1`
    set db_name  = `echo "${bc_rec}" | cut -d ':' -f 2`
    set col_name = `echo "${bc_rec}" | cut -d ':' -f 3`

    echo "INFO: copying reference data [${key_ref}] for sample [${db_name}/${col_name}/${bac_id}]"
    set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}
    set sample_data_reference = ${sample_data}/reference_fasta

    mkdir -p ${sample_data_reference}
    grep "^>" ${ref}.fa | gawk '{printf(">MAIN %s\n", substr($0,2));}' > ${sample_data_reference}/reference.fasta
    grep -v "^>" ${ref}.fa >> ${sample_data_reference}/reference.fasta
  end
end

rm include_270309412.txt
rm include_270309284.txt
rm 270309412.fa
rm 270309284.fa 


################### THIS IS THE START OF VIRUS SPECIFIC HANDLING ###############

foreach bc_rec ( `cat ${barcode_file_name} | grep -v "POSCTRL" | tr ' ' '_' | tr '\t' ':' | cut -d ':' -f 3,6,7 | sort -u | grep -v "LASKEN" | grep -v "givtest" | grep -v "vda"` )
  set bac_id   = `echo "${bc_rec}" | cut -d ':' -f 1`
  set db_name  = `echo "${bc_rec}" | cut -d ':' -f 2`
  set col_name = `echo "${bc_rec}" | cut -d ':' -f 3`

  set flu_a = 0
  switch ($db_name)
    case barda:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
      set flu_a = 1
    breaksw
    case giv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
      set flu_a = 1
    breaksw
    case giv3:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
      set flu_a = 1
    breaksw
    case piv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
      set flu_a = 1
    breaksw
    case swiv:
      echo "Using Influenza A reference data for database [${db_name}]"
      set ref_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/influenza_a_virus_full_length_NT
      set segments = "HA MP NA NP NS PA PB1 PB2"
      set seg_cov = "HA:175000 MP:100000 NA:145000 NP:155000 NS:89000 PA:220000 PB1:235000 PB2:235000"
      set flu_a = 1
    breaksw
    case rtv:
      echo "Using Rotavirus reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/rota_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/rota_virus_full_length_NT
      set segments = "VP1 VP2 VP3 VP4 NSP1 VP6 NSP3 NSP2 VP7 NSP4 NSP5"
      set seg_cov = "VP1:326700 VP2:268600 VP3:255000 VP4:232400 NSP1:151800 VP6:132300 NSP3:104100 NSP2:102200 VP7:103000 NSP4:70800 NSP5:62900"
      set flu_a = 0
    breaksw
    case gcv:
      echo "Using Coronavirus reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/corona_virus
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/corona_virus_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:3000000"
      set flu_a = 0
    breaksw
    case veev:
      echo "Using VEEV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/veev
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/veev_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:1200000"
      set flu_a = 0
    breaksw
    case hadv:
      echo "Using HADV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/hadv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/hadv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:4500000"
      set flu_a = 0
    breaksw
    case mpv:
      echo "Using MPV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/mpv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/mpv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:1335000"
      set flu_a = 0
    breaksw
    case norv:
      echo "Using NORV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/norv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/norv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:774600"
      set flu_a = 0
    breaksw
    case vzv:
      echo "Using VZV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/vzv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/vzv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:12500000"
      set flu_a = 0
    breaksw
    case rsv:
      echo "Using RSV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/rsv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/rsv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:1530000"
      set flu_a = 0
    breaksw
    case jev:
      echo "Using JEV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/jev
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/jev_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:1100000"
      set flu_a = 0
    breaksw
    case yfv:
      echo "Using YFV reference data for database [${db_name}]"
      set ref_dir      = /usr/local/projects/VHTNGS/reference_data/yfv
      set blast_db_dir = /usr/local/projects/VHTNGS/reference_data/yfv_full_length_NT
      set segments = "MAIN"
      set seg_cov = "MAIN:1090000"
      set flu_a = 0
    breaksw
    default:
      echo "Using no reference data for database [${db_name}]"
      set ref_dir      = ""
      set blast_db_dir = ""
      set segments = ""
      set seg_cov = ""
      set flu_a = 0
    breaksw
  endsw

  echo "INFO: processing data for [${db_name}/${col_name}/${bac_id}]"
  set sample_data = ${sample_data_root}/${db_name}/${col_name}/${bac_id}

  set sample_data_merged_solexa = ${sample_data}/merged_solexa
  set sample_data_merged_sff = ${sample_data}/merged_sff
  set sample_data_merged_sanger = ${sample_data}/merged_sanger
  set sample_data_merged_solexa_file = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq
  set sample_data_merged_solexa_file_t = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq.trimpoints
  set sample_data_merged_solexa_file_u = ${sample_data_merged_solexa}/${db_name}_${col_name}_${bac_id}.fastq.untrimmed
  set sample_data_merged_sff_file = ${sample_data_merged_sff}/${db_name}_${col_name}_${bac_id}.sff
  set sample_data_merged_sanger_file = ${sample_data_merged_sanger}/${db_name}_${col_name}_${bac_id}.fasta

  set seg_best_ref_dir = ${sample_data}/reference_fasta
  set best_refs_file = ${seg_best_ref_dir}/reference.fasta

  echo "INFO: mapping viral sequences for [${db_name}/${col_name}/${bac_id}]"
  set sample_mapping_dir = ${sample_data}/mapping
  if ( -d ${sample_mapping_dir} ) then
  else
    mkdir -p ${sample_mapping_dir}
  endif

  pushd ${sample_mapping_dir} >& /dev/null
    ln -s /usr/local/packages/clc-bfx-cell/license.properties ./

    set sff_exists = 0
    set input_read_files = ""
    foreach key (`ls -1 ${sample_data_merged_sff} | grep "\.[ACGT][ACGT][ACGT][ACGT]\." | cut -d '.' -f 2 | sort -u`)
      set input_read_files = `echo "${input_read_files} -q ${deconvolved_sff:r}.${key}.sff"`
      set sff_exists = 1
    end

    touch ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log
    if ( ${sff_exists} > 0 ) then
      echo "INFO: using clc_ref_assemble_long to find sff SNPs for [${db_name}_${col_name}_${bac_id}]"
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.cas \
        ${input_read_files} \
        -d ${best_refs_file}
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_454_only_gb_refs.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log
    endif
    cat ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log | \
      grep -v Nochange | \
      cut -d ':' -f 1 | \
      gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
             else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
      ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced

    touch ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced
    if ( `head -n 1 ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
      echo "INFO: using clc_ref_assemble_long to find fastq SNPs for [${db_name}_${col_name}_${bac_id}]"
      clc_ref_assemble_long \
        -s 0.95 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.cas \
        -q ${sample_data_merged_solexa_file} \
        -d ${best_refs_file}
      find_variations \
        -a ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.cas \
        -c 2 \
        -o ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs.new_contigs \
        -v \
        -f 0.2 >& ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log
      cat ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log | \
        grep -v Nochange | \
        cut -d ':' -f 1 | \
        gawk '{if($0 ~ /^[A-Z]/){s=$1;n=0; } \
               else if ($0 ~ /Difference/){l=$1; c=$5; n=0; printf("%s:%d:%s\n", s, l, c);}}' > \
        ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced
    endif

    if ( ${sff_exists} > 0 ) then
      if ( `head -n 1 ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced | wc -l` > 0 ) then
        sdiff \
          ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced \
          ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced | \
          grep -v "[<|>]" | \
          cut -f 1 > \
            ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced
      else
        cp \
          ${db_name}_${col_name}_${bac_id}_454_only_gb_refs_find_variations.log.reduced \
          ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced
      endif
    else
      cp \
        ${db_name}_${col_name}_${bac_id}_solexa_only_gb_refs_find_variations.log.reduced \
        ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced
    endif
 
    echo "INFO: building edited references based on common sff and fastq SNPs for [${db_name}_${col_name}_${bac_id}]"
    foreach seg ( `grep "^>" ${best_refs_file} | cut -d ' ' -f 1 | cut -c 2-` )
      nthseq -sequence ${best_refs_file} \
        -number `grep "^>" ${best_refs_file} | cut -d ' ' -f 1 | cut -c 2- | grep -n ${seg} | cut -d ':' -f 1` \
        -outseq ${db_name}_${col_name}_${bac_id}_${seg}.extracted >& /dev/null
      cat ${db_name}_${col_name}_${bac_id}_454_solexa_common_gb_refs_find_variations.log.reduced | \
        grep ${seg} | \
        cut -d ':' -f 2-3 | \
        tr '\n ' ' ' > ${db_name}_${col_name}_${bac_id}_${seg}.edits
      /usr/local/devel/DAS/software/resequencing/prod/data_analysis/delta2seq.pl \
        -r ${db_name}_${col_name}_${bac_id}_${seg}.extracted \
        -f ${db_name}_${col_name}_${bac_id}_${seg}.edits \
        -q ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited
      grep "^>" ${db_name}_${col_name}_${bac_id}_${seg}.extracted > \
        ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited.fasta
      grep -v "^>" ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited >> \
        ${db_name}_${col_name}_${bac_id}_${seg}.extracted.edited.fasta
    end
    set best_edited_refs_file = ${db_name}_${col_name}_${bac_id}_reference_edited.fasta
    cat ${db_name}_${col_name}_${bac_id}_*.extracted.edited.fasta > \
      ${best_edited_refs_file}

    echo "INFO: using 454 mapper for final chimera check for [${db_name}_${col_name}_${bac_id}]"

    if ( -d 454_mapping_best_refs_chimera_check ) then
      rm -Rf 454_mapping_best_refs_chimera_check
    endif
    newMapping 454_mapping_best_refs_chimera_check
    setRef 454_mapping_best_refs_chimera_check ${best_edited_refs_file}

    if ( `head -n 1 ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
      addRun 454_mapping_best_refs_chimera_check ${sample_data_merged_solexa_file}
    endif
    runProject -no 454_mapping_best_refs_chimera_check >& runProject_454_mapping_best_refs_chimera_check.log
    grep "Chimeric" 454_mapping_best_refs_chimera_check/mapping/454ReadStatus.txt | \
      gawk '{print $1}' > exclude_list.txt

    set final_sff_reads = ${db_name}_${col_name}_${bac_id}_final.sff
    set final_fastq_reads = ${db_name}_${col_name}_${bac_id}_final.fastq
    set final_fasta_reads = ${db_name}_${col_name}_${bac_id}_final.fasta

    touch ${final_fastq_reads}
    touch ${final_fastq_reads}.trimpoints
    touch ${final_fastq_reads}.untrimmed

    if ( `head -n 1 ${sample_data_merged_solexa_file} | wc -l` > 0 ) then
      /home/tstockwe/bin/fastqfile.pl \
        -o ${final_fastq_reads} \
        -e exclude_list.txt \
        -f ${sample_data_merged_solexa_file}

      cat ${final_fastq_reads} | \
        gawk '{t=NR % 4;\
               if(t==1){\
                 if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,qid,q)};\
                 sid=substr($0,2);\
               }\
               else if (t==2){s=$0;}\
               else if (t==3){qid=substr($0,2);}\
               else if (t==0){q=$0;}\
              }\
              END {\
                if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,qid,q)};\
                sid=substr($0,2);\
              }' | \
        sort | \
        gawk -F'\t' '{printf("@%s\n%s\n+%s\n%s\n", $1, $2, $3, $4);}' > ${final_fastq_reads}.sorted
      mv ${final_fastq_reads} ${final_fastq_reads}.unsorted
      mv ${final_fastq_reads}.sorted ${final_fastq_reads}

      grep "^@SOLEXA" ${final_fastq_reads} | cut -c 2- | sort > include_list.txt
      join -1 1 -2 1 \
        include_list.txt \
        ${sample_data_merged_solexa_file_t} | \
        tr ' ' '\t' > ${final_fastq_reads}.trimpoints

      /home/tstockwe/bin/fastqfile.pl \
        -o ${final_fastq_reads}.untrimmed \
        -i include_list.txt \
        -f ${sample_data_merged_solexa_file_u}

      cat ${final_fastq_reads}.untrimmed | \
        gawk '{t=NR % 4;\
               if(t==1){\
                 if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,qid,q)};\
                 sid=substr($0,2);\
               }\
               else if (t==2){s=$0;}\
               else if (t==3){qid=substr($0,2);}\
               else if (t==0){q=$0;}\
              }\
              END {\
                if(length(sid) > 0 ) {printf("%s\t%s\t%s\t%s\n", sid,s,qid,q)};\
                sid=substr($0,2);\
              }' | \
        sort | \
        gawk -F'\t' '{printf("@%s\n%s\n+%s\n%s\n", $1, $2, $3, $4);}' > ${final_fastq_reads}.untrimmed.sorted
      mv ${final_fastq_reads}.untrimmed.sorted ${final_fastq_reads}.untrimmed
    endif

    echo "INFO: running clc_ref_assemble_long for [${db_name}_${col_name}_${bac_id}]"

    set input_read_files = ""
    foreach key (`ls -1 ${sample_data_merged_sff} | grep "\.[ACGT][ACGT][ACGT][ACGT]\." | cut -d '.' -f 2 | sort -u`)
      set input_read_files = `echo "${input_read_files} -q ${final_sff_reads:r}.${key}.sff"`
    end

    if ( `head -n 1 ${final_fasta_reads} | wc -l` > 0 ) then
      set input_read_files = `echo "${input_read_files} -q ${final_fasta_reads}"`
    endif

    if ( `head -n 1 ${final_fastq_reads} | wc -l` > 0 ) then
      set input_read_files = `echo "${input_read_files} -q ${final_fastq_reads}"`
    endif

    clc_ref_assemble_long \
      -s 0.95 \
      -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
      ${input_read_files} \
      -d ${best_edited_refs_file}

    find_variations \
      -a ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.cas \
      -c 2 \
      -o ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs \
      -v \
      -f 0.2 >& ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs_find_variations.log

    if ( ${flu_a} > 0 ) then
      echo "INFO: running fluValidator for [${db_name}_${col_name}_${bac_id}]"
      /usr/local/devel/VIRIFX/software/Elvira/bin/fluValidator2 \
        --fasta ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs > \
        ${db_name}_${col_name}_${bac_id}_hybrid_edited_refs.new_contigs.fluValidator 
    endif
  popd >& /dev/null
end





























